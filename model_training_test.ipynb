{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Test - UNSW-NB15 Dataset\n",
    "Testing model training with real cybersecurity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load UNSW-NB15 Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "df_train = pd.read_csv('.venv/datasets/UNSW_NB15_training-set.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df_train.shape}\")\n",
    "print(f\"\\nColumns: {df_train.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for target column (usually 'label' or 'attack_cat')\n",
    "print(\"Dataset Info:\")\n",
    "print(df_train.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Missing Values:\")\n",
    "print(df_train.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Dataset Statistics:\")\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target distribution\n",
    "if 'label' in df_train.columns:\n",
    "    target_col = 'label'\n",
    "elif 'Label' in df_train.columns:\n",
    "    target_col = 'Label'\n",
    "elif 'attack_cat' in df_train.columns:\n",
    "    target_col = 'attack_cat'\n",
    "else:\n",
    "    # Find likely target column\n",
    "    target_col = df_train.columns[-1]\n",
    "\n",
    "print(f\"Target column: {target_col}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df_train[target_col].value_counts())\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "df_train[target_col].value_counts().plot(kind='bar')\n",
    "plt.title('Target Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "df = df_train.copy()\n",
    "\n",
    "# Handle missing values\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if target_col in categorical_cols:\n",
    "    categorical_cols.remove(target_col)\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in categorical_cols:\n",
    "    if df[col].nunique() < 50:  # Only encode if reasonable number of unique values\n",
    "        df[col] = pd.factorize(df[col])[0]\n",
    "    else:\n",
    "        df = df.drop(col, axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "# If target is categorical, encode it\n",
    "if y.dtype == 'object':\n",
    "    y = pd.factorize(y)[0]\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"\\nTraining target distribution:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest model...\")\n",
    "\n",
    "# Create and train model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModel training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Visualize top 15 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = 'models/unsw_nb15_threat_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "print(f\"Model file size: {os.path.getsize(model_path) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a few samples\n",
    "sample_indices = np.random.choice(len(X_test), 10, replace=False)\n",
    "samples = X_test.iloc[sample_indices]\n",
    "true_labels = y_test.iloc[sample_indices]\n",
    "predictions = model.predict(samples)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\"*50)\n",
    "for i, (true, pred) in enumerate(zip(true_labels, predictions)):\n",
    "    status = \"✓\" if true == pred else \"✗\"\n",
    "    print(f\"{status} Sample {i+1}: True={true}, Predicted={pred}\")\n",
    "\n",
    "accuracy_sample = accuracy_score(true_labels, predictions)\n",
    "print(\"=\"*50)\n",
    "print(f\"Sample accuracy: {accuracy_sample*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. ✅ Loading UNSW-NB15 dataset successfully\n",
    "2. ✅ Data preprocessing and feature engineering\n",
    "3. ✅ Training Random Forest classifier\n",
    "4. ✅ Model evaluation with multiple metrics\n",
    "5. ✅ Feature importance analysis\n",
    "6. ✅ Model persistence (saving)\n",
    "\n",
    "**The model is training properly with real cybersecurity data!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
